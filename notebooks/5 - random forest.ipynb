{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "In dit notebook zal het model Random Forest centraal staan. Hierbij worden er hard drives door het Random Forest model voorspeld."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Importeren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn import ensemble, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from graphviz import Source\n",
    "\n",
    "# Matplotlib voor grafische toepassingen en visualisaties\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het random forest model is een model gebruikt voor o.a. classificatie. Het is een verzameling van verschillende decision trees. Door gebruik te maken van bagging en feature randomness op deze decision trees wordt er een “forest” gecreeërd die bestaat uit meerdere trees die niet gecorreleerd zijn met elkaar. Deze forest is in de meeste gevallen meer accuraat dan één enkele tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De eerste stap zal zijn het kunnen predicten of een drive een failure heeft of niet aan de hand van de SMART-waardes. Deze SMART-waardes zijn 5, 9, 187, 188, 194, 197 en 198. Hiervoor is de Random Forest classification het beste doordat we te maken hebben met een boolean prediction value (het is een failure of geen failure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data importeren\n",
    "De data die gebruikt wordt is de data die gegenereerd is in het notebook `2 - sample analysing` (de dataset zonder 100% NaN waardes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('../data/sample_without_100nan.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "In de huidige dataset zitten er nog een aantal kolommen die geen toegevoegde waarde hebben voor het predicten van de failure. Deze kolommen zijn datum, model en serienummer. Hierdoor zullen deze eruit gehaald worden. Om toch de originele dataset later te kunnen gebruiken is er een keuze gemaakt om eerst een kopie te maken en daarmee verder te gaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_sample = sample.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del copy_sample['date']\n",
    "del copy_sample['serial_number']\n",
    "del copy_sample['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een ander gedeelte van het cleanen van data is het opvullen van lege waardes of het verwijderen van rows waar lege waardes in zitten. In 2 - sample analysing is te zien dat her percentage van lege waardes voor alle modellen minder dan 1% is. Hierdoor is er een keuze gemaakt om de rijen te verwijderen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(copy_sample, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "copy_sample.dropna(inplace=True)\n",
    "indices_to_keep = ~copy_sample.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "copy_sample[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals hierboven en hieronder te zien was de shape eerst 22008389 en na het deleten van de rows 22002242. Dat is een verschil van ongeveer 6000 rows. Dat is niks op een dataset van 22 miljoen rows.\n",
    "\n",
    "Daarnaast is al eerder aangegeven dat failure de kolom zal zijn die predict gaat worden. Hieronder wordt de failure op de Y axis gezet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_X = copy_sample.drop(['failure'], axis=1).values\n",
    "class_Y = copy_sample['failure'].values\n",
    "\n",
    "class_X.shape, class_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opsplitsen trainings- en validatieset\n",
    "Voor het opsplitsen van de data in een trainingsset en in een validatieset gebruiken we `Scikit-learn`. Een model wordt gebruikt om te trainen, en de andere wordt gebruikt om te testen.\n",
    "\n",
    "De data wordt opgesplit in een 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_X_train, class_X_test, class_Y_train, class_Y_test = train_test_split(class_X, class_Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daarna is nog een keer de shape te zien van zowel de Y als de X axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_X_train.shape, class_Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_X_test.shape, class_Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen van het model\n",
    "Hier wordt het model getrained. Dit wordt gedaan door middel van het Random Forest Classifier algoritme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = ensemble.RandomForestClassifier()\n",
    "# rf_model.fit(class_X_train, class_Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doordat het lang duurt om een model te trainen wordt het model opgeslagen zodat het meerdere keren gebruikt wordt. Dit wordt gedaan met pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(rf_model, open(\"../models/random_forest2.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met deze code kan het model weer geladen worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_saved = pickle.load(open(\"../models/random_forest.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_Y_pred = rf_model_saved.predict(class_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_acc = accuracy_score(class_Y_test, rf_Y_pred)\n",
    "\n",
    "print('Accuracy:', rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rf_model_saved, class_X_test, rf_Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.57311 to fit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dtree_render.png'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn= ['smart_5_raw', 'smart_9_raw', 'smart_187_raw', 'smart_188_raw', 'smart_194_raw', 'smart_197_raw', 'smart_198_raw']\n",
    "\n",
    "graph = Source( tree.export_graphviz(rf_model_saved.estimators_[0], out_file=None, feature_names= fn))\n",
    "graph.format = 'png'\n",
    "graph.render('dtree_render',view=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94cba30e1f8486639541d41298ec9cc4daf793c14917176b9d457b6f40f35a70"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
